# GROQ DEPLOYMENT VALIDATION PROTOCOL

**Comprehensive Testing & Validation Framework for Dual-Speed Cognition**
**Version:** 1.0
**Date:** 2025-10-11
**Architect:** Claude (Master Strategist)

---

## PROTOCOL OVERVIEW

This protocol ensures the Groq integration deploys safely, performs reliably, and maintains constitutional alignment. It defines **5 validation phases** with specific success criteria, rollback triggers, and escalation procedures.

**Constitutional Principle:** *"Trust, but verify. Speed without safety is recklessness."*

---

## PHASE 1: PRE-DEPLOYMENT VALIDATION (Local Environment)

**Duration:** 15-30 minutes
**Location:** Development machine (PandaA16)
**Responsibility:** Codex (Forgemaster)

### 1.1 CODE QUALITY CHECKS

```bash
# Run all unit tests
cd /Users/panda/Desktop/UBOS/02_FORGE/packages/groq_integration/
python3 -m pytest test_groq_integration.py -v

# Expected output:
# test_fast_think ............................ PASSED
# test_web_search ........................... PASSED
# test_wolfram .............................. PASSED
# test_reason ............................... PASSED
# test_code_exec ............................ PASSED
# test_local_scout .......................... PASSED
# test_retry_logic .......................... PASSED
# test_fallback_on_api_failure .............. PASSED
# test_token_limit_enforcement .............. PASSED
# test_cost_tracking ........................ PASSED
#
# ==================== 10 passed in 12.34s ====================
```

**SUCCESS CRITERIA:**
- ‚úÖ All unit tests pass (10/10)
- ‚úÖ No import errors
- ‚úÖ Mock API responses handled correctly
- ‚úÖ Retry/fallback logic functional
- ‚úÖ Token limits enforced (max 4096 tokens)

**FAILURE RESPONSE:**
- ‚ùå If any test fails ‚Üí Fix code before deployment
- ‚ùå Do NOT proceed to Phase 2 until all tests pass

---

### 1.2 ENVIRONMENT VALIDATION

```bash
# Verify API credentials
python3 -c "
import os
from dotenv import load_dotenv
load_dotenv('.env.groq')

groq_key = os.getenv('GROQ_API_KEY')
wolfram_key = os.getenv('WOLFRAM_APP_ID')

assert groq_key and groq_key.startswith('gsk_'), 'Invalid GROQ_API_KEY'
assert wolfram_key and len(wolfram_key) > 5, 'Invalid WOLFRAM_APP_ID'

print('‚úÖ Environment variables validated')
"
```

**SUCCESS CRITERIA:**
- ‚úÖ GROQ_API_KEY present and valid format
- ‚úÖ WOLFRAM_APP_ID present (if using wolfram tool)
- ‚úÖ Optional config vars set (GROQ_TIMEOUT_SECONDS, GROQ_MAX_RETRIES)

**FAILURE RESPONSE:**
- ‚ùå Missing credentials ‚Üí Request from Captain
- ‚ùå Invalid format ‚Üí Regenerate API keys

---

### 1.3 LIVE API CONNECTIVITY TEST

```bash
# Test real Groq API call (not mocked)
python3 -c "
from groq_client import GroqClient

client = GroqClient()
result = client.fast_think('System check: respond with current timestamp')

print(f'‚úÖ API Response: {result[:100]}...')
print(f'‚úÖ Connection successful')
"
```

**SUCCESS CRITERIA:**
- ‚úÖ API responds within 10 seconds
- ‚úÖ Valid JSON response received
- ‚úÖ No authentication errors
- ‚úÖ Token usage logged correctly

**FAILURE RESPONSE:**
- ‚ùå Timeout ‚Üí Check network connectivity
- ‚ùå Auth error ‚Üí Verify API key validity
- ‚ùå Rate limit ‚Üí Wait or request key rotation

---

### 1.4 DUAL-SPEED BRAIN INTEGRATION TEST

```bash
# Test dual-speed brain with mock local LLM
python3 -c "
from dual_speed_brain import DualSpeedBrain

brain = DualSpeedBrain()

# Test scout mode
result = brain.scout('Quick test')
assert len(result) > 0, 'Scout mode failed'
print('‚úÖ Scout mode functional')

# Test mode selection logic
assert brain._should_scout('urgent status check') == True
assert brain._should_deliberate('strategic constitutional decision') == True
print('‚úÖ Mode selection logic functional')
"
```

**SUCCESS CRITERIA:**
- ‚úÖ DualSpeedBrain imports successfully
- ‚úÖ Mode selection logic works correctly
- ‚úÖ Scout mode routes to Groq
- ‚úÖ Deliberate mode routes to local (mocked)
- ‚úÖ Adaptive mode chains both

**FAILURE RESPONSE:**
- ‚ùå Import error ‚Üí Check dependencies
- ‚ùå Logic error ‚Üí Review mode selection keywords

---

### 1.5 SECURITY & PERMISSIONS CHECK

```bash
# Verify .env.groq file permissions
ls -la .env.groq

# Expected output:
# -rw------- 1 user user 256 Oct 11 14:30 .env.groq
#  ^^ Only owner can read/write

# Verify no credentials in code
grep -r "gsk_" groq_client.py dual_speed_brain.py
# Expected: No matches (credentials only in .env)
```

**SUCCESS CRITERIA:**
- ‚úÖ .env.groq has 600 permissions (owner-only read/write)
- ‚úÖ No hardcoded credentials in source code
- ‚úÖ Audit logging enabled by default

**FAILURE RESPONSE:**
- ‚ùå Wrong permissions ‚Üí `chmod 600 .env.groq`
- ‚ùå Hardcoded secrets ‚Üí Remove and use environment variables

---

## PHASE 2: DEPLOYMENT TO BALAUR

**Duration:** 5-10 minutes
**Location:** The Balaur (100.94.145.78)
**Responsibility:** Codex (automated via deploy_groq_to_balaur.sh)

### 2.1 AUTOMATED DEPLOYMENT SCRIPT

```bash
# Execute deployment from development machine
./deploy_groq_to_balaur.sh

# Script performs:
# 1. SSH connectivity check to Balaur
# 2. Create /srv/janus/tools/ directory (if not exists)
# 3. Create /srv/janus/config/ directory (if not exists)
# 4. SCP groq_client.py to /srv/janus/tools/
# 5. SCP dual_speed_brain.py to /srv/janus/tools/
# 6. SCP .env.groq to /srv/janus/config/ (with 600 permissions)
# 7. Install Python dependencies: pip3 install groq python-dotenv
# 8. Verify file integrity (checksums)
# 9. Create audit log directory: mkdir -p /srv/janus/logs/
# 10. Run smoke tests (Phase 3)
```

**SUCCESS CRITERIA:**
- ‚úÖ SSH connection to Balaur successful
- ‚úÖ All 5 files copied successfully
- ‚úÖ File permissions preserved (600 for .env.groq)
- ‚úÖ Python dependencies installed
- ‚úÖ No file corruption (checksums match)

**FAILURE RESPONSE:**
- ‚ùå SSH timeout ‚Üí Check Balaur connectivity
- ‚ùå Permission denied ‚Üí Verify SSH key auth
- ‚ùå Disk full ‚Üí Clear space on Balaur
- ‚ùå Dependency error ‚Üí Install missing system packages

---

### 2.2 POST-DEPLOYMENT VERIFICATION

```bash
# SSH into Balaur and verify deployment
ssh panda@100.94.145.78

# Check files exist
ls -lh /srv/janus/tools/groq_client.py
ls -lh /srv/janus/tools/dual_speed_brain.py
ls -lh /srv/janus/config/.env.groq

# Check permissions
stat -c "%a %n" /srv/janus/config/.env.groq
# Expected: 600 /srv/janus/config/.env.groq

# Check Python can import
cd /srv/janus/tools/
python3 -c "import groq_client; import dual_speed_brain; print('‚úÖ Imports successful')"
```

**SUCCESS CRITERIA:**
- ‚úÖ All files present at expected locations
- ‚úÖ .env.groq has 600 permissions
- ‚úÖ Python imports work without errors
- ‚úÖ groq package installed (`pip3 list | grep groq`)

**FAILURE RESPONSE:**
- ‚ùå Missing files ‚Üí Re-run deployment script
- ‚ùå Import errors ‚Üí Check Python version (requires 3.8+)
- ‚ùå Package missing ‚Üí `pip3 install groq python-dotenv`

---

## PHASE 3: SMOKE TESTS (Balaur Environment)

**Duration:** 3-5 minutes
**Location:** The Balaur
**Responsibility:** Automated test script (run by Codex)

### 3.1 BASIC FUNCTIONALITY TEST

```bash
# On Balaur, run smoke tests
cd /srv/janus/tools/
python3 << 'EOF'
import sys
import os
sys.path.insert(0, '/srv/janus/tools')

from groq_client import GroqClient
from dotenv import load_dotenv

# Load environment
load_dotenv('/srv/janus/config/.env.groq')

# Test 1: Initialize client
try:
    client = GroqClient()
    print("‚úÖ Test 1: Client initialization successful")
except Exception as e:
    print(f"‚ùå Test 1 FAILED: {e}")
    sys.exit(1)

# Test 2: Fast think (quick API call)
try:
    response = client.fast_think("System check: respond with 'OK'")
    assert len(response) > 0, "Empty response"
    print(f"‚úÖ Test 2: fast_think() functional - Response: {response[:50]}")
except Exception as e:
    print(f"‚ùå Test 2 FAILED: {e}")
    sys.exit(1)

# Test 3: Environment variables loaded
try:
    groq_key = os.getenv('GROQ_API_KEY')
    assert groq_key is not None, "GROQ_API_KEY not loaded"
    print("‚úÖ Test 3: Environment variables loaded")
except Exception as e:
    print(f"‚ùå Test 3 FAILED: {e}")
    sys.exit(1)

print("\n‚úÖ‚úÖ‚úÖ ALL SMOKE TESTS PASSED ‚úÖ‚úÖ‚úÖ")
EOF
```

**SUCCESS CRITERIA:**
- ‚úÖ Client initializes without errors
- ‚úÖ fast_think() returns valid response
- ‚úÖ Environment variables load correctly
- ‚úÖ No exceptions thrown

**FAILURE RESPONSE:**
- ‚ùå Import error ‚Üí Reinstall dependencies
- ‚ùå API error ‚Üí Check network connectivity from Balaur
- ‚ùå Env error ‚Üí Verify .env.groq path and contents

---

### 3.2 DUAL-SPEED BRAIN SMOKE TEST

```bash
# Test dual-speed brain integration on Balaur
cd /srv/janus/tools/
python3 << 'EOF'
import sys
sys.path.insert(0, '/srv/janus/tools')

from dual_speed_brain import DualSpeedBrain

# Initialize (this will need mock local LLM initially)
try:
    brain = DualSpeedBrain()
    print("‚úÖ DualSpeedBrain initialized")
except Exception as e:
    print(f"‚ö†Ô∏è  DualSpeedBrain init warning: {e}")
    print("   (Expected if local LLM not yet integrated)")

# Test mode detection logic
keywords_scout = brain._should_scout("urgent status check")
keywords_deliberate = brain._should_deliberate("strategic constitutional decision")

assert keywords_scout == True, "Scout detection failed"
assert keywords_deliberate == True, "Deliberate detection failed"

print("‚úÖ Mode selection logic functional")
print("\n‚úÖ DUAL-SPEED BRAIN SMOKE TEST PASSED")
EOF
```

**SUCCESS CRITERIA:**
- ‚úÖ DualSpeedBrain class loads
- ‚úÖ Mode selection logic works
- ‚ö†Ô∏è  Local LLM integration warning is acceptable (Phase 4 task)

**FAILURE RESPONSE:**
- ‚ùå Class load error ‚Üí Check syntax errors in dual_speed_brain.py
- ‚ùå Logic error ‚Üí Review keyword lists and conditions

---

## PHASE 4: INTEGRATION TESTS (Full Stack)

**Duration:** 10-15 minutes
**Location:** The Balaur
**Responsibility:** Codex + Captain (manual verification)

### 4.1 ALL ORACLE METHODS TEST

```bash
# Test all 6 Groq oracle methods
cd /srv/janus/tools/
python3 << 'EOF'
import sys
sys.path.insert(0, '/srv/janus/tools')

from groq_client import GroqClient
import json

client = GroqClient()
results = {}

# Test 1: fast_think
try:
    r = client.fast_think("What is 2+2?")
    results['fast_think'] = '‚úÖ PASS' if len(r) > 0 else '‚ùå FAIL'
except Exception as e:
    results['fast_think'] = f'‚ùå FAIL: {e}'

# Test 2: web_search
try:
    r = client.web_search("latest AI news", max_results=3)
    results['web_search'] = '‚úÖ PASS' if r.get('results') else '‚ùå FAIL'
except Exception as e:
    results['web_search'] = f'‚ùå FAIL: {e}'

# Test 3: wolfram
try:
    r = client.wolfram("integrate x^2")
    results['wolfram'] = '‚úÖ PASS' if len(r) > 0 else '‚ùå FAIL'
except Exception as e:
    results['wolfram'] = f'‚ö†Ô∏è  SKIP: {e} (Wolfram key may not be set)'

# Test 4: reason
try:
    r = client.reason("Should we deploy on Friday?", effort='low')
    results['reason'] = '‚úÖ PASS' if r.get('reasoning_steps') else '‚ùå FAIL'
except Exception as e:
    results['reason'] = f'‚ùå FAIL: {e}'

# Test 5: code_exec (if available)
try:
    r = client.code_exec("print(2+2)", language='python')
    results['code_exec'] = '‚úÖ PASS' if r.get('output') else '‚ùå FAIL'
except Exception as e:
    results['code_exec'] = f'‚ö†Ô∏è  SKIP: {e} (May not be enabled)'

# Test 6: local_scout
try:
    r = client.local_scout("GROQ", path='/srv/janus')
    results['local_scout'] = '‚úÖ PASS' if len(r) > 0 else '‚ùå FAIL'
except Exception as e:
    results['local_scout'] = f'‚ùå FAIL: {e}'

# Print results table
print("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
print("‚ïë     ORACLE METHODS TEST RESULTS        ‚ïë")
print("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£")
for method, status in results.items():
    print(f"‚ïë {method:20s} {status:15s} ‚ïë")
print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")

# Count passes
passes = sum(1 for v in results.values() if '‚úÖ PASS' in v)
total = len(results)
print(f"Result: {passes}/{total} tests passed")

if passes >= 4:  # Minimum 4 core methods must pass
    print("‚úÖ INTEGRATION TEST PASSED (minimum threshold met)")
else:
    print("‚ùå INTEGRATION TEST FAILED (too many failures)")
    sys.exit(1)
EOF
```

**SUCCESS CRITERIA:**
- ‚úÖ At least 4/6 oracle methods pass
- ‚úÖ Core methods (fast_think, web_search, reason, local_scout) all pass
- ‚ö†Ô∏è  wolfram, code_exec may be optional/skipped

**FAILURE RESPONSE:**
- ‚ùå <4 methods pass ‚Üí Investigate API errors, check logs
- ‚ùå Core method fails ‚Üí Review error messages, check network/auth

---

### 4.2 FALLBACK & RETRY LOGIC TEST

```bash
# Test retry logic and fallback behavior
cd /srv/janus/tools/
python3 << 'EOF'
import sys
sys.path.insert(0, '/srv/janus/tools')

from groq_client import GroqClient

client = GroqClient(max_retries=2, timeout_seconds=5)

# Test 1: Retry on timeout (simulate with very short timeout)
print("Test 1: Retry logic...")
try:
    # This may timeout and retry
    response = client.fast_think("test", timeout_override=0.1)
    print("‚ö†Ô∏è  Request succeeded (no retry needed)")
except Exception as e:
    print(f"‚úÖ Retry logic engaged: {type(e).__name__}")

# Test 2: Graceful error handling
print("\nTest 2: Error handling...")
try:
    # Invalid API call (should handle gracefully)
    client._client.api_key = "invalid_key_for_testing"
    response = client.fast_think("test")
    print("‚ùå Should have raised error for invalid key")
except Exception as e:
    print(f"‚úÖ Graceful error handling: {type(e).__name__}")

print("\n‚úÖ FALLBACK & RETRY TEST PASSED")
EOF
```

**SUCCESS CRITERIA:**
- ‚úÖ Retry logic attempts multiple times on timeout
- ‚úÖ Errors handled gracefully (no crashes)
- ‚úÖ Appropriate exceptions raised with clear messages

---

### 4.3 AUDIT LOGGING TEST

```bash
# Verify audit logging writes correctly
cd /srv/janus/tools/
python3 << 'EOF'
import sys
import os
import json
sys.path.insert(0, '/srv/janus/tools')

from groq_client import GroqClient

# Ensure log directory exists
os.makedirs('/srv/janus/logs', exist_ok=True)

client = GroqClient(audit_log_path='/srv/janus/logs/groq_audit.jsonl')

# Make a test call
response = client.fast_think("Audit log test")

# Check log file exists and has content
log_path = '/srv/janus/logs/groq_audit.jsonl'
if os.path.exists(log_path):
    with open(log_path, 'r') as f:
        lines = f.readlines()
        if lines:
            last_entry = json.loads(lines[-1])
            print(f"‚úÖ Audit log entry: {last_entry}")
            assert 'timestamp' in last_entry
            assert 'tool' in last_entry
            assert 'tokens_used' in last_entry
            print("‚úÖ AUDIT LOGGING TEST PASSED")
        else:
            print("‚ùå Log file empty")
else:
    print("‚ùå Log file not created")
EOF
```

**SUCCESS CRITERIA:**
- ‚úÖ Log file created at /srv/janus/logs/groq_audit.jsonl
- ‚úÖ Valid JSON entries written
- ‚úÖ Entries contain required fields (timestamp, tool, tokens_used, etc.)

---

### 4.4 PERFORMANCE BENCHMARK

```bash
# Measure actual performance on Balaur
cd /srv/janus/tools/
python3 << 'EOF'
import sys
import time
sys.path.insert(0, '/srv/janus/tools')

from groq_client import GroqClient

client = GroqClient()

# Benchmark fast_think speed
prompt = "Explain quantum computing in one sentence."

start = time.time()
response = client.fast_think(prompt)
elapsed = time.time() - start

tokens_approx = len(response.split()) * 1.3  # Rough token estimate
tokens_per_sec = tokens_approx / elapsed

print(f"Response time: {elapsed:.2f}s")
print(f"Estimated tokens: {tokens_approx:.0f}")
print(f"Tokens/sec: {tokens_per_sec:.1f}")

if elapsed < 15:
    print("‚úÖ Performance meets target (<15s for fast queries)")
else:
    print("‚ö†Ô∏è  Performance slower than expected (investigate network latency)")

# Compare to local LLM baseline (if available)
print("\nSpeed advantage over local: ~23x faster (87 t/s vs 3.78 t/s)")
EOF
```

**SUCCESS CRITERIA:**
- ‚úÖ Fast queries complete in <15 seconds
- ‚úÖ Web search queries complete in <20 seconds
- ‚úÖ Speed advantage confirmed (10x+ faster than local baseline)

---

## PHASE 5: BURN-IN TEST (24-Hour Monitoring)

**Duration:** 24 hours
**Location:** The Balaur (production environment)
**Responsibility:** Janus-in-Balaur + Captain (monitoring)

### 5.1 PRODUCTION USAGE MONITORING

```bash
# Set up continuous monitoring script
cat > /srv/janus/scripts/monitor_groq_health.sh << 'EOF'
#!/bin/bash

# Monitor Groq integration health
LOG_FILE="/srv/janus/logs/groq_audit.jsonl"
METRICS_FILE="/srv/janus/logs/dual_speed_metrics.jsonl"

echo "=== Groq Integration Health Check ==="
echo "Time: $(date)"

# Check 1: Recent API calls
echo ""
echo "Recent API activity (last 10 calls):"
tail -n 10 $LOG_FILE | jq -r '[.timestamp, .tool, .status] | @tsv' 2>/dev/null || echo "No logs yet"

# Check 2: Error rate
echo ""
echo "Error analysis (last 100 calls):"
TOTAL=$(tail -n 100 $LOG_FILE | wc -l)
ERRORS=$(tail -n 100 $LOG_FILE | grep -c '"status":"error"' || echo 0)
ERROR_RATE=$(echo "scale=1; $ERRORS * 100 / $TOTAL" | bc 2>/dev/null || echo "N/A")
echo "Errors: $ERRORS / $TOTAL ($ERROR_RATE%)"

if [ "$ERROR_RATE" != "N/A" ] && [ $(echo "$ERROR_RATE > 10" | bc) -eq 1 ]; then
    echo "‚ö†Ô∏è  WARNING: Error rate above 10%"
else
    echo "‚úÖ Error rate within acceptable range"
fi

# Check 3: Cost tracking
echo ""
echo "Cost estimate (today):"
TOKEN_COUNT=$(tail -n 1000 $LOG_FILE | jq -s 'map(.tokens_used // 0) | add' 2>/dev/null || echo 0)
COST_EST=$(echo "scale=4; $TOKEN_COUNT * 0.08 / 1000000" | bc 2>/dev/null || echo "N/A")
echo "Tokens used: $TOKEN_COUNT"
echo "Est. cost: \$$COST_EST"

if [ "$COST_EST" != "N/A" ] && [ $(echo "$COST_EST > 1.00" | bc) -eq 1 ]; then
    echo "‚ö†Ô∏è  WARNING: Daily cost exceeds $1.00 threshold"
else
    echo "‚úÖ Cost within budget"
fi

# Check 4: Performance
echo ""
echo "Average response times (last 50 calls):"
tail -n 50 $LOG_FILE | jq -s 'map(.response_time_sec // 0) | add / length' 2>/dev/null || echo "N/A"

echo ""
echo "=== End Health Check ==="
EOF

chmod +x /srv/janus/scripts/monitor_groq_health.sh

# Run health check every 4 hours
echo "0 */4 * * * /srv/janus/scripts/monitor_groq_health.sh >> /srv/janus/logs/health_checks.log 2>&1" | crontab -
```

**Monitoring Metrics:**

| Metric                    | Target              | Alert Threshold      |
|---------------------------|---------------------|----------------------|
| **API Success Rate**      | >95%               | <90%                 |
| **Avg Response Time**     | <15s (scout mode)  | >25s                 |
| **Error Rate**            | <5%                | >10%                 |
| **Daily Cost**            | <$0.20             | >$1.00               |
| **Fallback Events**       | <5 per day         | >20 per day          |

---

### 5.2 MISSION EXECUTION TEST

**Execute 4 first missions during burn-in period:**

#### Mission 1: Precedent Scout
```bash
# Have Janus execute a precedent search using dual-speed mode
# Mode: Adaptive (Groq web_search ‚Üí Local synthesis)
# Expected: 60s total, high-quality constitutional mapping
```

#### Mission 2: Emergency Triage
```bash
# Simulate urgent system issue
# Mode: Scout (Groq fast_think + local_scout)
# Expected: <15s response, actionable recommendations
```

#### Mission 3: Research-Informed Decision
```bash
# Request decision on strategic question requiring external intelligence
# Mode: Adaptive (Groq web_search ‚Üí Local deliberation)
# Expected: 50s total, synthesized external + internal knowledge
```

#### Mission 4: Philosophy Node Deep Dive
```bash
# Request deep philosophical analysis
# Mode: Adaptive (Groq fast_think ‚Üí Local deep reasoning)
# Expected: 55s total, constitutional alignment verified
```

**SUCCESS CRITERIA:**
- ‚úÖ All 4 missions complete successfully
- ‚úÖ Mode selection appropriate for each mission type
- ‚úÖ Response quality meets strategic standards
- ‚úÖ Performance targets met (time, cost, accuracy)

---

### 5.3 ALERTING & ESCALATION

**Automated Alerts:**

```python
# Alert conditions (to be implemented in monitoring script)

def check_alert_conditions():
    # Alert Level 1: Warning (log only)
    if error_rate > 5%:
        log_warning("Error rate elevated: {error_rate}%")

    if avg_response_time > 20s:
        log_warning("Response times degraded: {avg_response_time}s")

    # Alert Level 2: Attention Required (notify Captain)
    if error_rate > 10%:
        notify_captain("‚ö†Ô∏è Groq error rate critical: {error_rate}%")

    if daily_cost > $0.50:
        notify_captain("‚ö†Ô∏è Groq cost elevated: ${daily_cost}")

    # Alert Level 3: Critical (automatic rollback)
    if error_rate > 25%:
        trigger_rollback("‚ùå Groq integration critically failing")

    if daily_cost > $5.00:
        trigger_emergency_stop("‚ùå Cost runaway detected")
```

**Escalation Path:**

1. **Level 1 (Warning):** Log to `/srv/janus/logs/alerts.log`, continue operation
2. **Level 2 (Attention):** Notify Captain via mission_archive.jsonl entry, continue with monitoring
3. **Level 3 (Critical):** Execute rollback protocol, disable Groq integration, revert to local-only

---

## ROLLBACK PROTOCOL

**Trigger Conditions:**
- API error rate >25% sustained for >1 hour
- Daily cost exceeds $5.00
- Critical security incident detected
- Constitutional alignment violation
- Manual rollback requested by Captain

**Rollback Procedure:**

```bash
# Execute rollback script
cat > /srv/janus/scripts/rollback_groq.sh << 'EOF'
#!/bin/bash

echo "üîÑ INITIATING GROQ INTEGRATION ROLLBACK"

# Step 1: Disable Groq client
mv /srv/janus/tools/groq_client.py /srv/janus/tools/groq_client.py.disabled
mv /srv/janus/tools/dual_speed_brain.py /srv/janus/tools/dual_speed_brain.py.disabled

# Step 2: Archive logs for analysis
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
mkdir -p /srv/janus/logs/rollback_$TIMESTAMP/
cp /srv/janus/logs/groq_audit.jsonl /srv/janus/logs/rollback_$TIMESTAMP/
cp /srv/janus/logs/dual_speed_metrics.jsonl /srv/janus/logs/rollback_$TIMESTAMP/

# Step 3: Notify
echo "$(date): Groq integration rolled back due to: $1" >> /srv/janus/logs/rollback_history.log

# Step 4: Restore local-only mode
echo "‚úÖ Rollback complete. System reverted to local-only LLM."
echo "   Logs archived to: /srv/janus/logs/rollback_$TIMESTAMP/"
echo "   Reason: $1"
EOF

chmod +x /srv/janus/scripts/rollback_groq.sh
```

**Post-Rollback Actions:**
1. Analyze logs in rollback archive
2. Identify root cause (API issues, code bugs, config errors)
3. Fix issues in development environment
4. Re-run Phases 1-3 validation
5. Attempt redeployment only after fixes verified

---

## SUCCESS METRICS SUMMARY

| Phase | Duration | Success Criteria | Go/No-Go Decision |
|-------|----------|------------------|-------------------|
| **Phase 1** | 15-30 min | All tests pass locally | MUST PASS to proceed |
| **Phase 2** | 5-10 min | Clean deployment to Balaur | MUST PASS to proceed |
| **Phase 3** | 3-5 min | Basic API calls work | MUST PASS to proceed |
| **Phase 4** | 10-15 min | 4/6 oracles functional | MINIMUM threshold |
| **Phase 5** | 24 hours | <10% error rate, <$0.20/day | Full production approval |

**Final Validation Checklist:**

```
PRE-DEPLOYMENT:
‚òê All unit tests pass (10/10)
‚òê API credentials validated
‚òê Live connectivity test successful
‚òê Dual-speed brain logic verified
‚òê Security audit clean

DEPLOYMENT:
‚òê Files copied to Balaur successfully
‚òê Permissions correct (600 for .env.groq)
‚òê Dependencies installed
‚òê Smoke tests pass

INTEGRATION:
‚òê Core oracle methods functional (4/6 minimum)
‚òê Retry/fallback logic works
‚òê Audit logging operational
‚òê Performance meets targets (<15s scout mode)

BURN-IN:
‚òê 24-hour monitoring complete
‚òê Error rate <10%
‚òê Daily cost <$0.20
‚òê All 4 first missions successful
‚òê No critical incidents

PRODUCTION APPROVAL:
‚òê Captain approves for full autonomous use
‚òê Monitoring scripts running
‚òê Rollback procedure tested
‚òê Documentation complete
```

---

## CONSTITUTIONAL ALIGNMENT VERIFICATION

**Final checkpoint before production approval:**

```yaml
constitutional_alignment_checklist:
  lion_sanctuary_principles:
    - empowerment_over_constraint: ‚úÖ Dual-speed expands capabilities
    - transparency: ‚úÖ All API calls audited and logged
    - user_sovereignty: ‚úÖ Captain retains rollback authority
    - privacy: ‚úÖ No PII sent to external APIs without consent

  janus_citizenship:
    - autonomous_decision_making: ‚úÖ Mode selection is autonomous
    - strategic_alignment: ‚úÖ Serves Republic velocity goals
    - ethical_reasoning: ‚úÖ Constitutional checks in deliberate mode
    - continuous_improvement: ‚úÖ Performance metrics enable learning

  operational_excellence:
    - reliability: ‚úÖ Fallback to local ensures uptime
    - cost_consciousness: ‚úÖ Budget limits enforced
    - security: ‚úÖ Credential isolation, audit trail
    - performance: ‚úÖ 2-24x speed improvements measured
```

**Final Approval Authority:** Captain BROlinni

---

**END OF VALIDATION PROTOCOL**

**Status:** Ready for execution upon Codex completion of implementation files.

**Next Action:** Await Codex delivery of 5 implementation files, then execute Phase 1 validation.
